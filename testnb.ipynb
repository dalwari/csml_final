{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fba8b397",
   "metadata": {},
   "source": [
    "Setup & imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "53736f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer  # or the specific tokenizer you use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "639441fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file loaded successfully!\n",
      "Shape: (270033, 5)\n",
      "Columns: ['note_id', 'input', 'target', 'input_tokens', 'target_tokens']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "note_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "input",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "target",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "input_tokens",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "target_tokens",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "8bfb7b58-8668-4937-8b93-f64f9b8e27cc",
       "rows": [
        [
         "0",
         "10000032-DS-21",
         "<SEX> F <SERVICE> MEDICINE <ALLERGIES> No Known Allergies / Adverse Drug Reactions <ATTENDING> ___ <CHIEF COMPLAINT> Worsening ABD distension and pain <MAJOR SURGICAL OR INVASIVE PROCEDURE> Paracentesis <HISTORY OF PRESENT ILLNESS> ___ HCV cirrhosis c/b ascites, hiv on ART, h/o IVDU, COPD, bioplar, PTSD, presented from OSH ED with worsening abd distension over past week. Pt reports self-discontinuing lasix and spirnolactone ___ weeks ago, because she feels like \"they don't do anything\" and that she \"doesn't want to put more chemicals in her.\" She does not follow Na-restricted diets. In the past week, she notes that she has been having worsening abd distension and discomfort. She denies ___ edema, or SOB, or orthopnea. She denies f/c/n/v, d/c, dysuria. She had food poisoning a week ago from eating stale cake (n/v 20 min after food ingestion), which resolved the same day. She denies other recent illness or sick contacts. She notes that she has been noticing gum bleeding while brushing her teeth in recent weeks. she denies easy bruising, melena, BRBPR, hemetesis, hemoptysis, or hematuria. Because of her abd pain, she went to OSH ED and was transferred to ___ for further care. Per ED report, pt has brief period of confusion - she did not recall the ultrasound or bloodwork at osh. She denies recent drug use or alcohol use. She denies feeling confused, but reports that she is forgetful at times. In the ED, initial vitals were 98.4 70 106/63 16 97%RA Labs notable for ALT/AST/AP ___ ___: ___, Tbili1.6, WBC 5K, platelet 77, INR 1.6 <PAST MEDICAL HISTORY> 1. HCV Cirrhosis 2. No history of abnormal Pap smears. 3. She had calcification in her breast, which was removed previously and per patient not, it was benign. 4. For HIV disease, she is being followed by Dr. ___ Dr. ___. 5. COPD 6. Past history of smoking. 7. She also had a skin lesion, which was biopsied and showed skin cancer per patient report and is scheduled for a complete removal of the skin lesion in ___ of this year. 8. She also had another lesion in her forehead with purple discoloration. It was biopsied to exclude the possibility of ___'s sarcoma, the results is pending. 9. A 15 mm hypoechoic lesion on her ultrasound on ___ and is being monitored by an MRI. 10. History of dysplasia of anus in ___. 11. Bipolar affective disorder, currently manic, mild, and PTSD. 12. History of cocaine and heroin use. <SOCIAL HISTORY> ___ <FAMILY HISTORY> She a total of five siblings, but she is not talking to most of them. She only has one brother that she is in touch with and lives in ___. She is not aware of any known GI or liver disease in her family. Her last alcohol consumption was one drink two months ago. No regular alcohol consumption. Last drug use ___ years ago. She quit smoking a couple of years ago. <PHYSICAL EXAM> VS: 98.1 107/61 78 18 97RA General: in NAD HEENT: CTAB, anicteric sclera, OP clear Neck: supple, no LAD CV: RRR,S1S2, no m/r/g Lungs: CTAb, prolonged expiratory phase, no w/r/r Abdomen: distended, mild diffuse tenderness, +flank dullness, cannot percuss liver/spleen edge ___ distension GU: no foley Ext: wwp, no c/e/e, + clubbing Neuro: AAO3, converse normally, able to recall 3 times after 5 minutes, CN II-XII intact Discharge: PHYSICAL EXAMINATION: VS: 98 105/70 95 General: in NAD HEENT: anicteric sclera, OP clear Neck: supple, no LAD CV: RRR,S1S2, no m/r/g Lungs: CTAb, prolonged expiratory phase, no w/r/r Abdomen: distended but improved, TTP in RUQ, GU: no foley Ext: wwp, no c/e/e, + clubbing Neuro: AAO3, CN II-XII intact <PERTINENT RESULTS> ___ 10: 25PM GLUCOSE-109* UREA N-25* CREAT-0.3* SODIUM-138 POTASSIUM-3.4 CHLORIDE-105 TOTAL CO2-27 ANION GAP-9 ___ 10: 25PM estGFR-Using this ___ 10: 25PM ALT(SGPT)-100* AST(SGOT)-114* ALK PHOS-114* TOT BILI-1.6* ___ 10: 25PM LIPASE-77* ___ 10: 25PM ALBUMIN-3.3* ___ 10: 25PM WBC-5.0# RBC-4.29 HGB-14.3 HCT-42.6 MCV-99* MCH-33.3* MCHC-33.5 RDW-15.7* ___ 10: 25PM NEUTS-70.3* LYMPHS-16.5* MONOS-8.1 EOS-4.2* BASOS-0.8 ___ 10: 25PM PLT COUNT-71* ___ 10: 25PM ___ PTT-30.9 ___ ___ 10: 25PM ___ . CXR: No acute cardiopulmonary process. U/S: 1. Nodular appearance of the liver compatible with cirrhosis. Signs of portal hypertension including small amount of ascites and splenomegaly. 2. Cholelithiasis. 3. Patent portal veins with normal hepatopetal flow. Diagnostic para attempted in the ED, unsuccessful. On the floor, pt c/o abd distension and discomfort. <MEDICATIONS ON ADMISSION> The Preadmission Medication list is accurate and complete. 1. Furosemide 20 mg PO DAILY 2. Spironolactone 50 mg PO DAILY 3. Albuterol Inhaler 2 PUFF IH Q4H: PRN wheezing, SOB 4. Raltegravir 400 mg PO BID 5. Emtricitabine-Tenofovir (Truvada) 1 TAB PO DAILY 6. Nicotine Patch 14 mg TD DAILY 7. Ipratropium Bromide Neb 1 NEB IH Q6H SOB <DISCHARGE MEDICATIONS> 1. Albuterol Inhaler 2 PUFF IH Q4H: PRN wheezing, SOB 2. Emtricitabine-Tenofovir (Truvada) 1 TAB PO DAILY 3. Furosemide 40 mg PO DAILY RX *furosemide 40 mg 1 tablet(s) by mouth Daily Disp #*30 Tablet Refills: *3 4. Ipratropium Bromide Neb 1 NEB IH Q6H SOB 5. Nicotine Patch 14 mg TD DAILY 6. Raltegravir 400 mg PO BID 7. Spironolactone 50 mg PO DAILY 8. Acetaminophen 500 mg PO Q6H: PRN pain <DISCHARGE DISPOSITION> Home <DISCHARGE DIAGNOSIS> Ascites from Portal HTN <DISCHARGE CONDITION> Mental Status: Clear and coherent. Level of Consciousness: Alert and interactive. Activity Status: Ambulatory - Independent. <FOLLOWUP INSTRUCTIONS> ___ <DISCHARGE INSTRUCTIONS> Dear Ms. ___, It was a pleasure taking care of you! You came to us with stomach pain and worsening distension. While you were here we did a paracentesis to remove 1.5L of fluid from your belly. We also placed you on you 40 mg of Lasix and 50 mg of Aldactone to help you urinate the excess fluid still in your belly. As we discussed, everyone has a different dose of lasix required to make them urinate and it's likely that you weren't taking a high enough dose. Please take these medications daily to keep excess fluid off and eat a low salt diet. You will follow up with Dr. ___ in liver clinic and from there have your colonoscopy and EGD scheduled. Of course, we are always here if you need us. We wish you all the best! Your ___ Team. ",
         "___ HCV cirrhosis c/b ascites, hiv on ART, h/o IVDU, COPD, bioplar, PTSD, presented from OSH ED with worsening abd distension over past week and confusion. # Ascites - p/w worsening abd distension and discomfort for last week. likely ___ portal HTN given underlying liver disease, though no ascitic fluid available on night of admission. No signs of heart failure noted on exam. This was ___ to med non-compliance and lack of diet restriction. SBP negative diuretics: > Furosemide 40 mg PO DAILY > Spironolactone 50 mg PO DAILY, chosen over the usual 100mg dose d/t K+ of 4.5. CXR was wnl, UA negative, Urine culture blood culture negative. Pt was losing excess fluid appropriately with stable lytes on the above regimen. Pt was scheduled with current PCP for ___ check upon discharge. Pt was scheduled for new PCP with Dr. ___ at ___ and follow up in Liver clinic to schedule outpatient screening EGD and ___. ",
         "1946",
         "231"
        ],
        [
         "1",
         "10000032-DS-22",
         "<SEX> F <SERVICE> MEDICINE <ALLERGIES> Percocet <ATTENDING> ___. <CHIEF COMPLAINT> abdominal fullness and discomfort <MAJOR SURGICAL OR INVASIVE PROCEDURE> ___ diagnostic paracentesis ___ therapeutic paracentesis <HISTORY OF PRESENT ILLNESS> ___ with HIV on HAART, COPD, HCV cirrhosis complicated by ascites and HE admitted with abdominal distention and pain. She was admitted to ___ for the same symptoms recently and had 3L fluid removed (no SBP) three days ago and felt better. Since discharge, her abdomen has become increasingly distended with pain. This feels similar to prior episodes of ascites. Her diuretics were recently decreased on ___ due to worsening hyponatremia 128 and hyperkalemia 5.1. Patient states she has been compliant with her HIV and diuretic medications but never filled out the lactulose prescription. She states she has had ___ BMs daily at home. She has had some visual hallucinations and forgetfulness. Her appetite has been poor. In the ED, initial vitals were 98.9 88 116/88 18 97% RA. CBC near baseline, INR 1.4, Na 125, Cr 0.6. AST and ALT mildly above baseline 182 and 126 and albumin 2.8. Diagnostic para with 225 WBC, 7% PMN, total protein 0.3. UA with few bact, 6 WBC, mod leuk, neg nitr, but contaminated with 6 epi. CXR clear. RUQ US with no PV thrombus, moderate ascites. She was given ondansetron 4mg IV and morphine 2.5mg IV x1 in the ED. On the floor, she is feeling improved but still has abdominal distention and discomfort. ROS: +Abdominal distention and pain. No black/bloody stools. No ___ pain or swelling. No fevers or chills. Denies chest pain, nausea, vomiting. No dysuria or frequency. <PAST MEDICAL HISTORY> 1. HCV Cirrhosis 2. No history of abnormal Pap smears. 3. She had calcification in her breast, which was removed previously and per patient not, it was benign. 4. For HIV disease, she is being followed by Dr. ___ Dr. ___. 5. COPD 6. Past history of smoking. 7. She also had a skin lesion, which was biopsied and showed skin cancer per patient report and is scheduled for a complete removal of the skin lesion in ___ of this year. 8. She also had another lesion in her forehead with purple discoloration. It was biopsied to exclude the possibility of ___'s sarcoma, the results is pending. 9. A 15 mm hypoechoic lesion on her ultrasound on ___ and is being monitored by an MRI. 10. History of dysplasia of anus in ___. 11. Bipolar affective disorder, currently manic, mild, and PTSD. 12. History of cocaine and heroin use. <SOCIAL HISTORY> ___ <FAMILY HISTORY> She a total of five siblings, but she is not talking to most of them. She only has one brother that she is in touch with and lives in ___. She is not aware of any known GI or liver disease in her family. <PHYSICAL EXAM> ADMISSION PHYSICAL EXAM: VS: T98.1 105/57 79 20 97RA 44.6kg GENERAL: Thin chronically ill appearing woman in no acute distress HEENT: Sclera anicteric, MMM, no oral lesions HEART: RRR, normal S1 S2, no murmurs LUNGS: Clear, no wheezes, rales, or rhonchi ABD: Significant distention with visible veins, bulging flanks, nontender to palpation, tympanitic on percussion, normal bowel sounds EXT: no ___ edema, 2+ DP and ___ pulses NEURO: alert and oriented, not confused, no asterixis DISCHARGE PE: VS: T 98.4 BP 95/55 (SBP ___ HR 80 RR 18 O2 95RA I/O 240/150 this am GENERAL: Thin chronically ill appearing woman in no acute distress HEENT: Sclera anicteric, MMM, no oral lesions HEART: RRR, normal S1 S2, no murmurs LUNGS: Clear, no wheezes, rales, or rhonchi ABD: Significant distention with visible veins, bulging flanks, nontender to palpation, tympanitic on percussion, normal bowel sounds EXT: no ___ edema, 2+ DP and ___ pulses NEURO: alert and oriented, not confused, no asterixis <PERTINENT RESULTS> LABS ON ADMISSION: ___ 04: 10PM BLOOD ___ ___ Plt ___ ___ 04: 10PM BLOOD ___ ___ ___ 04: 10PM BLOOD ___ ___ ___ 04: 10PM BLOOD ___ ___ ___ 04: 10PM BLOOD ___ ___ 04: 39PM BLOOD ___ LABS ON DISCHARGE: ___ 05: 10AM BLOOD ___ ___ Plt ___ ___ 05: 10AM BLOOD ___ ___ ___ 05: 10AM BLOOD ___ ___ ___ 05: 10AM BLOOD ___ ___ ___ 05: 10AM BLOOD ___ MICRO: ___ 10: 39 pm URINE Source: ___. **FINAL REPORT ___ URINE CULTURE (Final ___: MIXED BACTERIAL FLORA ( >= 3 COLONY TYPES), CONSISTENT WITH SKIN AND/OR GENITAL CONTAMINATION. ___ 7: 00 pm PERITONEAL FLUID PERITONEAL FLUID. GRAM STAIN (Final ___: 1+ (<1 per 1000X FIELD): POLYMORPHONUCLEAR LEUKOCYTES. NO MICROORGANISMS SEEN. This is a concentrated smear made by cytospin method, please refer to hematology for a quantitative white blood cell count.. FLUID CULTURE (Final ___: NO GROWTH. ANAEROBIC CULTURE (Preliminary): NO GROWTH. ___ 7: 00 pm PERITONEAL FLUID PERITONEAL FLUID. GRAM STAIN (Final ___: 1+ (<1 per 1000X FIELD): POLYMORPHONUCLEAR LEUKOCYTES. NO MICROORGANISMS SEEN. This is a concentrated smear made by cytospin method, please refer to hematology for a quantitative white blood cell count.. FLUID CULTURE (Final ___: NO GROWTH. ANAEROBIC CULTURE (Preliminary): NO GROWTH. Diagnositc Para: ___ 07: 00PM ASCITES ___ ___ ___ 07: 00PM ASCITES ___ IMAGING: ___ CXR- No acute cardiopulmonary abnormality. ___ RUQ US- 1. Extremely coarse and nodular liver echotexture consistent with a history of cirrhosis. 2. Moderate ascites. 3. Patent portal vein. <MEDICATIONS ON ADMISSION> The Preadmission Medication list is accurate and complete. 1. Albuterol Inhaler 2 PUFF IH Q6H: PRN wheezing, SOB 2. ___ (Truvada) 1 TAB PO DAILY 3. Furosemide 20 mg PO DAILY 4. Raltegravir 400 mg PO BID 5. Spironolactone 50 mg PO DAILY 6. Acetaminophen 500 mg PO Q6H: PRN pain,fever 7. Tiotropium Bromide 1 CAP IH DAILY 8. Rifaximin 550 mg PO BID 9. Calcium Carbonate 1250 mg PO BID 10. Lactulose 15 mL PO TID 11. Sulfameth/Trimethoprim DS 1 TAB PO DAILY <DISCHARGE MEDICATIONS> 1. Acetaminophen 500 mg PO Q6H: PRN pain,fever 2. Albuterol Inhaler 2 PUFF IH Q6H: PRN wheezing, SOB 3. Calcium Carbonate 1250 mg PO BID 4. ___ (Truvada) 1 TAB PO DAILY 5. Furosemide 40 mg PO DAILY 6. Lactulose 15 mL PO TID 7. Raltegravir 400 mg PO BID 8. Rifaximin 550 mg PO BID 9. Sulfameth/Trimethoprim DS 1 TAB PO DAILY 10. Tiotropium Bromide 1 CAP IH DAILY <DISCHARGE DISPOSITION> Home <DISCHARGE DIAGNOSIS> Primary: diuretic refractory ascites Secondary: HCV cirrhosis, HIV, hyponatremia, COPD <DISCHARGE CONDITION> Mental Status: Clear and coherent. Level of Consciousness: Alert and interactive. Activity Status: Ambulatory - Independent. <FOLLOWUP INSTRUCTIONS> ___ <DISCHARGE INSTRUCTIONS> Dear ___, ___ was a pleasure to take care of you at ___ ___. You were admitted with abdominal fullness and pain from your ascites. You had a diagnostic and therapeutic paracentesis with 4.3 L removed. Your spironolactone was discontinued because your potassium was high. Your lasix was increased to 40mg daily. You are scheduled for another paracentesis on ___ prior to your other appointments that day. Please call tomorrow to find out the time of the paracentesis. Please continue to follow a low sodium diet and fluid restriction. You should call your liver doctor or return to the emergency room if you have abdominal pain, fever, chills, confusion, or other concerning symptoms. Sincerely, Your ___ medical team ",
         "___ with HIV on HAART, HCV cirrhosis with ascites and HE, h/o IVDU, COPD, bipolar disorder presents with abdominal discomfort due to ___ ascites. # ASCITES. Now diuretic refractory given last tap was three days ago with 3L removed and she has already built up moderate ascites. Infectious workup negative, with CXR clear, UA contaminated but not grossly positive so will f/u culture, diagnostic para with only 225 WBC, RUQ US with no PV thrombus. Compliant with diuretics but not following low sodium diet or fluid restriction. Dr. ___ discussed possible TIPS in the office but due to lung disease, that was on hold pending further cardiac evaluation. Diuretics were recently decreased due to hyponatremia and hyperkalemia. Held spironolactone for now due to K 5.2 and increased lasix 20 -> 40. No evidence of severe hyponatremia (Na<120) or renal failure Cr>2.0 to stop diuretics at present. Diagnostic paracentesis negative for infection. Ascitic total protein 0.3 so warrants SBP prophylaxis (<1.0) and fortunately already on Bactrim for PCP prophylaxis which would be appropriate for SBP ppx also. Patient did admit to eating pizza and some ___ food prior to admission. She had therapeutic paracentesis with 4.3L removed and received 37.5G albumin IV post procedure. She felt much better with resolution of abdominal discomfort. Patient is scheduled for repeat paracentesis as outpatient on ___. # HEPATIC ENCEPHALOPATHY. History of HE from Hep C cirrhosis. Now with mild encephalopathy (hallucinations and forgetfulness) due to medication noncompliance, but not acutely encephalopathic and without asterixis on exam. Infectious workup negative thus far. Continue lactulose 30mL TID and titrate to 3 BMs daily and continue rifaximin 550mg BID. # HYPONATREMIA. Na 125 on admission, 128 four days ago, and 135 one month ago. Likely due to third spacing from worsening ascites and fluid overload. 1.5L fluid restriction, low salt diet. S/p therapeutic paracentesis with albumin replacement. # CIRRHOSIS, HEPATITIS C. MELD score of 10 and Child's ___ class B on this admission. Now decompensated due to ascites. Hepatitis C genotype IIIB. Dr. ___ starting ___ and ___ with patient in clinic and the insurance process was started by her office. No history of EGD, needs this as outpatient for varices screening. # NUTRITION. Unclear if truly compliant with low salt diet. Poor oral intake. Low albumin 2.8 on admission. Met with nutrition. # COAGULOPATHY. INR 1.4 four days ago. No evidence of active bleeding. Very mild thrombocytopenia with plts 143. # HIV. Most recent CD4 173. On HAART. No established ID provider. Continue Truvada and Isentress, Bactrim DS daily for PCP ___. Needs outpatient ID appointment # COPD. Stable. States she is on intermittent home O2 for comfort at night and with abdominal distentiom. Continued home COPD meds and home O2 as needed **Transitional Issues** - Discontinued spironolactone ___ elevated potassium - Increased furosemide to 40mg daily - Please recheck electrolytes at next visit - Had paracentesis ___ with 4.3 L removed, received 37.5G albumin - Needs outpatient ID provider - ___ needs more frequent paracentesis ",
         "2183",
         "810"
        ],
        [
         "2",
         "10000117-DS-21",
         "<SEX> F <SERVICE> MEDICINE <ALLERGIES> omeprazole <ATTENDING> ___. <CHIEF COMPLAINT> dysphagia <MAJOR SURGICAL OR INVASIVE PROCEDURE> Upper endoscopy ___ <HISTORY OF PRESENT ILLNESS> ___ w/ anxiety and several years of dysphagia who p/w worsened foreign body sensation. She describes feeling as though food gets stuck in her neck when she eats. She put herself on a pureed diet to address this over the last 10 days. When she has food stuck in the throat, she almost feels as though she cannot breath, but she denies trouble breathing at any other time. She does not have any history of food allergies or skin rashes. In the ED, initial vitals: 97.6 81 148/83 16 100% RA Imaging showed: CXR showed a prominent esophagus Consults: GI was consulted. Pt underwent EGD which showed a normal appearing esophagus. Biopsies were taken. Currently, she endorses anxiety about eating. She would like to try eating here prior to leaving the hospital. <PAST MEDICAL HISTORY> - GERD - Hypercholesterolemia - Kidney stones - Mitral valve prolapse - Uterine fibroids - Osteoporosis - Migraine headaches <SOCIAL HISTORY> ___ <FAMILY HISTORY> + HTN - father + Dementia - father <PHYSICAL EXAM> - ADMISSION/DISCHARGE EXAM - VS: 97.9 PO 109 / 71 70 16 97 ra GEN: Thin anxious woman, lying in bed, no acute distress HEENT: Moist MM, anicteric sclerae, NCAT, PERRL, EOMI NECK: Supple without LAD, no JVD PULM: CTABL no w/c/r COR: RRR (+)S1/S2 no m/r/g ABD: Soft, non-tender, non-distended, +BS, no HSM EXTREM: Warm, well-perfused, no ___ edema NEURO: CN II-XII grossly intact, motor function grossly normal, sensation grossly intact <PERTINENT RESULTS> - ADMISSION LABS - ___ 08: 27AM BLOOD WBC-5.0 RBC-4.82 Hgb-14.9 Hct-44.4 MCV-92 MCH-30.9 MCHC-33.6 RDW-12.1 RDWSD-41.3 Plt ___ ___ 08: 27AM BLOOD ___ PTT-28.6 ___ ___ 08: 27AM BLOOD Glucose-85 UreaN-8 Creat-0.9 Na-142 K-3.6 Cl-104 HCO3-22 AnGap-20 ___ 08: 27AM BLOOD ALT-11 AST-16 LD(LDH)-154 AlkPhos-63 TotBili-1.0 ___ 08: 27AM BLOOD Albumin-4.8 - IMAGING - CXR ___: IMPRESSION: Prominent esophagus on lateral view, without air-fluid level. Given the patient's history and radiographic appearance, barium swallow is indicated either now or electively. NECK X-ray ___: IMPRESSION: Within the limitation of plain radiography, no evidence of prevertebral soft tissue swelling or soft tissue mass in the neck. EGD: ___ Impression: Hiatal hernia Angioectasia in the stomach Angioectasia in the duodenum (biopsy, biopsy) Otherwise normal EGD to third part of the duodenum Recommendations: - no obvious anatomic cause for the patient's symptoms - follow-up biopsy results to rule out eosinophilic esophagitis - follow-up with Dr. ___ if biopsies show eosinophilic esophagitis <MEDICATIONS ON ADMISSION> The Preadmission Medication list is accurate and complete. 1. Omeprazole 20 mg PO BID <DISCHARGE MEDICATIONS> 1. Omeprazole 20 mg PO BID <DISCHARGE DISPOSITION> Home <DISCHARGE DIAGNOSIS> PRIMARY DIAGNOSIS: -dysphagia and foreign body sensation SECONDARY DIAGNOSIS: -GERD <DISCHARGE CONDITION> Mental Status: Clear and coherent. Level of Consciousness: Alert and interactive. Activity Status: Ambulatory - Independent. <FOLLOWUP INSTRUCTIONS> ___ <DISCHARGE INSTRUCTIONS> Dear Ms. ___, You were hospitalized at ___. You came in due to difficulty swallowing. You had an endoscopy to look for any abnormalities in the esophagus. Thankfully, this was normal. They took biopsies, and you will be called with the results. You should have a test called a barium swallow as an outpatient. We wish you all the best! -Your ___ Team ",
         "Ms. ___ is a ___ with history of GERD who presents with subacute worsening of dysphagia and foreign body sensation. This had worsened to the point where she placed herself on a pureed diet for the last 10 days. She underwent CXR which showed a prominent esophagus but was otherwise normal. She was evaluated by Gastroenterology and underwent an upper endoscopy on ___. This showed a normal appearing esophagus. Biopsies were taken. TRANSITIONAL ISSUES: -f/u biopsies from EGD -if results show eosinophilic esophagitis, follow-up with Dr. ___. ___ for management -pt should undergo barium swallow as an outpatient for further workup of her dysphagia -f/u with ENT as planned #Code: Full (presumed) ",
         "1060",
         "172"
        ],
        [
         "3",
         "10000117-DS-22",
         "<SEX> F <SERVICE> ORTHOPAEDICS <ALLERGIES> omeprazole / Iodine and Iodide Containing Products / hallucinogens <ATTENDING> ___. <CHIEF COMPLAINT> Left hip pain <MAJOR SURGICAL OR INVASIVE PROCEDURE> Status post left CRPP ___, ___ <HISTORY OF PRESENT ILLNESS> REASON FOR CONSULT: Femur fracture HPI: ___ female presents with the above fracture s/p mechanical fall. This morning, pt was walking ___, when dog pulled on leash. Pt fell on L hip. Immediate pain. ___ ___ with movement. Denies Head strike, LOC or blood thinners. Denies numbness or weakness in the extremities. <PAST MEDICAL HISTORY> - GERD - Hypercholesterolemia - Kidney stones - Mitral valve prolapse - Uterine fibroids - Osteoporosis - Migraine headaches <SOCIAL HISTORY> ___ <FAMILY HISTORY> + HTN - father + Dementia - father <PHYSICAL EXAM> General: Well-appearing female in no acute distress. Left Lower extremity: - Skin intact - No deformity, edema, ecchymosis, erythema, induration - Soft, non-tender thigh and leg - Full, painless ROM knee, and ankle - Fires ___ - SILT S/S/SP/DP/T distributions - 1+ ___ pulses, WWP <MEDICATIONS ON ADMISSION> The Preadmission Medication list is accurate and complete. 1. Lactaid (lactase) 3,000 unit oral DAILY: PRN 2. Calcium Citrate + D (calcium citrate-vitamin D3) 315-200 mg-unit oral DAILY <DISCHARGE MEDICATIONS> 1. Acetaminophen 1000 mg PO Q6H: PRN Pain - Mild/Fever 2. Bisacodyl 10 mg PO/PR DAILY: PRN Constipation 3. Docusate Sodium 100 mg PO BID 4. Enoxaparin Sodium 40 mg SC QHS RX *enoxaparin 40 mg/0.4 mL 40 mg Subcutaneously Nightly Disp #*30 Syringe Refills: *0 5. OxyCODONE (Immediate Release) ___ mg PO Q4H: PRN Pain - Moderate RX *oxycodone 5 mg 1 tablet(s) by mouth q4 PRN Disp #*25 Tablet Refills: *0 6. Senna 8.6 mg PO BID 7. Calcium Citrate + D (calcium citrate-vitamin D3) 315-200 mg-unit oral DAILY 8. Lactaid (lactase) 3,000 unit oral DAILY: PRN 9. Multivitamins 1 TAB PO DAILY 10. Vitamin D 400 UNIT PO DAILY <DISCHARGE DISPOSITION> Home With Service Facility: ___ <DISCHARGE DIAGNOSIS> Left valgus impacted femoral neck fracture <DISCHARGE CONDITION> AVSS NAD, A&Ox3 LLE: Incision well approximated. Dressing clean and dry. Fires FHL, ___, TA, GCS. SILT ___ n distributions. 1+ DP pulse, wwp distally. <FOLLOWUP INSTRUCTIONS> ___ <DISCHARGE INSTRUCTIONS> INSTRUCTIONS AFTER ORTHOPAEDIC SURGERY: - You were in the hospital for orthopedic surgery. It is normal to feel tired or \"washed out\" after surgery, and this feeling should improve over the first few days to week. - Resume your regular activities as tolerated, but please follow your weight bearing precautions strictly at all times. ACTIVITY AND WEIGHT BEARING: - Weightbearing as tolerated left lower extremity MEDICATIONS: 1) Take Tylenol ___ every 6 hours around the clock. This is an over the counter medication. 2) Add oxycodone as needed for increased pain. Aim to wean off this medication in 1 week or sooner. This is an example on how to wean down: Take 1 tablet every 3 hours as needed x 1 day, then 1 tablet every 4 hours as needed x 1 day, then 1 tablet every 6 hours as needed x 1 day, then 1 tablet every 8 hours as needed x 2 days, then 1 tablet every 12 hours as needed x 1 day, then 1 tablet every before bedtime as needed x 1 day. Then continue with Tylenol for pain. 3) Do not stop the Tylenol until you are off of the narcotic medication. 4) Per state regulations, we are limited in the amount of narcotics we can prescribe. If you require more, you must contact the office to set up an appointment because we cannot refill this type of pain medication over the phone. 5) Narcotic pain relievers can cause constipation, so you should drink eight 8oz glasses of water daily and continue following the bowel regimen as stated on your medication prescription list. These meds (senna, colace, miralax) are over the counter and may be obtained at any pharmacy. 6) Do not drink alcohol, drive a motor vehicle, or operate machinery while taking narcotic pain relievers. 7) Please take all medications as prescribed by your physicians at discharge. 8) Continue all home medications unless specifically instructed to stop by your surgeon. ANTICOAGULATION: - Please take Lovenox daily for 4 weeks ",
         "The patient presented to the emergency department and was evaluated by the orthopedic surgery team. The patient was found to have a left valgus impacted femoral neck fracture and was admitted to the orthopedic surgery service. The patient was taken to the operating room on ___ for left closed reduction and percutaneous pinning of hip, which the patient tolerated well. For full details of the procedure please see the separately dictated operative report. The patient was taken from the OR to the PACU in stable condition and after satisfactory recovery from anesthesia was transferred to the floor. The patient was initially given IV fluids and IV pain medications, and progressed to a regular diet and oral medications by POD#1. The patient was given ___ antibiotics and anticoagulation per routine. The patient's home medications were continued throughout this hospitalization. The patient worked with ___ who determined that discharge to home with services was appropriate. The ___ hospital course was otherwise unremarkable. At the time of discharge the patient's pain was well controlled with oral medications, incisions were clean/dry/intact, and the patient was voiding/moving bowels spontaneously. The patient is weightbearing as tolerated in the left lower extremity, and will be discharged on Lovenox for DVT prophylaxis. The patient will follow up with Dr. ___ routine. A thorough discussion was had with the patient regarding the diagnosis and expected post-discharge course including reasons to call the office or return to the hospital, and all questions were answered. The patient was also given written instructions concerning precautionary instructions and the appropriate follow-up care. The patient expressed readiness for discharge. ",
         "1195",
         "330"
        ],
        [
         "4",
         "10000248-DS-10",
         "<SEX> M <SERVICE> MEDICINE <ALLERGIES> No Known Allergies / Adverse Drug Reactions <ATTENDING> ___. <CHIEF COMPLAINT> Right flank bruising and pain s/p fall <MAJOR SURGICAL OR INVASIVE PROCEDURE> None <HISTORY OF PRESENT ILLNESS> Mr. ___ is a ___ with history of factor VIII deficiency who presents with right neck swelling after snowboarding accident. The patient reports that he fell while snowboarding with loss of consciousness on ___. He was initially seen at ___ where CT imaging of head/neck showed no intracranial hemorrhage. A CTA neck showed a thickened right platysma muscle with surrounding hematoma and a focus of active contrast extravasation within the right platysma muscle. He also developed a right shoulder hematoma although shoulder plain films didn't show acute abnormality. He was seen by ___ Hematology and gave him one dose of DDAVP IV. A factor VIII assay was 139 and vW level was >200 per report. Per report, his hemoglobin decreased from 13.2 on ___ to 11.6 on ___. Repeat imaging in the morning showed stable injuries. The patient saw his hematologist on ___ and was found to have a hemoglobin of 10.4. Because of the continued mild decrease, the patient followed up with his PCP ___ ___ at which time his hemoglobin was 9.9. He was found to have an enlarging flank hematoma, thus was referred given concern for retroperitoneal bleed. The patient has been using DDAVP intranasally intermittently since the accident. He denies lightheadedness or palpitations, any increase in neck swelling over the course of the week. He does endorse pain in his right shoulder ___ resting, ___ moving), though this has improved over the course of the week. In the ED, initial vital signs were 99.2 87 124/75 18 100%/RA. Initial labs demonstrated hemoglobin 10.6, though repeat was 9.7. Chemistries and coags were unremarkable. FVIII activity was 103. A CTAP was performed which demonstrated muscular hemorrhage along the flank, but no retroperitoneal bleed on preliminary read. The patient's outpatient hematologist, Dr. ___, was contacted and it was decided to give the patient desmopressin 0.3mg/kg IV. The patient was then admitted for futher management. Per review of records, the patient has a history of significant bleeding after his circumcision, requiring blood transfusion. Throughout childhood, he also had a tendency to bruise easily. He was tested and found to have ___ disease. Later, after wisdom tooth extraction, the patient experienced late (e.g. ___ days later) bleeding despite treatment with DDAVP. The patient was retested by a hematologist associated with the ___ and was diagnosed with hemophilia A. His FVIII activity has been checked on multiple occasions, sometimes testing normal, though has been as low as ~50. Upon arrival to the floor, the patient is comfortable without complaint. Review of Systems: (+) per HPI (-) fever, chills, night sweats, headache, vision changes, rhinorrhea, congestion, sore throat, cough, shortness of breath, chest pain, abdominal pain, nausea, vomiting, diarrhea, constipation, BRBPR, melena, hematochezia, dysuria, hematuria. <PAST MEDICAL HISTORY> -Factor VIII deficiency (mild) <SOCIAL HISTORY> ___ <FAMILY HISTORY> The patient's mother had tendency to bleed. <PHYSICAL EXAM> ON ADMISSION VS: 98 120/40 64 20 100RA GENERAL: lying flat in bed, no acute distress HEENT: NCAT, MMM, OP clear NECK: Supple CARDIAC: RRR, S1/S2, no murmurs, gallops, or rubs LUNG: Generally CTA b/l ABDOMEN: Soft, non-tender, non-distended EXTREMITIES: Warm, well-perfused PULSES: 2+ DP pulses bilaterally NEURO: CN II-XII intact SKIN: Hematomas on right aspect of neck and flank ON DISCHARGE Vitals: 98.0, 100-120/40-58, 66, 20, 99 on RA GENERAL: lying flat in bed, no acute distress HEENT: NCAT, MMM, OP clear NECK: Supple CARDIAC: RRR, S1/S2, no murmurs, gallops, or rubs LUNG: Generally CTA b/l ABDOMEN: Soft, non-tender, non-distended EXTREMITIES: Warm, well-perfused PULSES: 2+ DP pulses bilaterally NEURO: CN II-XII intact SKIN: Hematomas on right aspect of neck and flank <PERTINENT RESULTS> ADMISSION, DISCHARGE, PERTINENT LABS: ___ 07: 03PM BLOOD WBC-6.6 RBC-3.58* Hgb-10.6*# Hct-29.8*# MCV-83 MCH-29.6 MCHC-35.6* RDW-14.7 Plt ___ ___ 07: 03PM BLOOD Neuts-69.7 ___ Monos-7.2 Eos-2.4 Baso-0.2 ___ 07: 03PM BLOOD ___ PTT-35.2 ___ ___ 07: 03PM BLOOD Plt ___ ___ 07: 03PM BLOOD FacVIII-103 ___ 07: 03PM BLOOD Glucose-93 UreaN-15 Creat-0.8 Na-139 K-4.1 Cl-101 HCO3-28 AnGap-14 ___ 11: 00PM BLOOD WBC-6.6 RBC-3.30* Hgb-9.7* Hct-27.0* MCV-82 MCH-29.4 MCHC-36.0* RDW-14.7 Plt ___ ___ 07: 25AM BLOOD WBC-5.2 RBC-3.14* Hgb-9.3* Hct-26.2* MCV-83 MCH-29.7 MCHC-35.7* RDW-14.6 Plt ___ ___ 03: 25PM BLOOD WBC-6.3 RBC-3.27* Hgb-9.9* Hct-27.1* MCV-83 MCH-30.3 MCHC-36.5* RDW-14.7 Plt ___ ___ 07: 50PM URINE Color-Yellow Appear-Clear Sp ___ ___ 07: 50PM URINE Blood-NEG Nitrite-NEG Protein-30 Glucose-NEG Ketone-NEG Bilirub-NEG Urobiln-NEG pH-6.0 Leuks-NEG ___ 07: 50PM URINE RBC-<1 WBC-1 Bacteri-FEW Yeast-NONE Epi-0 ___ 07: 50PM URINE Mucous-RARE IMAGING/STUDIES: ___ CT A/P Acute hemorrhage along right posterior flank musculature and probably layering over it, only partly imaged and hard to distinguish musculature from hemorrhage. No active extravasation seen. Probable old hematoma along posterior left flank. <MEDICATIONS ON ADMISSION> The Preadmission Medication list is accurate and complete. 1. Desmopressin Nasal ___ mcg NAS PRN bleeding <DISCHARGE MEDICATIONS> 1. Acetaminophen 1000 mg PO Q8H pain 2. Desmopressin Nasal ___ mcg NAS PRN bleeding 3. Outpatient Lab Work CBC on ___ or ___. Last hemoglobin 9.9 ___ ___. <DISCHARGE DISPOSITION> Home <DISCHARGE DIAGNOSIS> PRIMARY: - Acute muscular hematoma, right flank - Hemophilia, factor VIII deficiency <DISCHARGE CONDITION> Mental Status: Clear and coherent. Level of Consciousness: Alert and interactive. Activity Status: Ambulatory - Independent. <FOLLOWUP INSTRUCTIONS> ___ <DISCHARGE INSTRUCTIONS> Mr. ___, It was our pleasure caring for you at ___ ___. You were admitted with bruising on your right side and low blood counts after a snowboarding fall. With your history of hemophilia, it was important to evaluate internal bleeding which did show a right muscular flank blood collection. Your facotr VIII level was 103 and you received IV DDAVP under our care. Your blood counts were stable to improved on the day of admission. It is important that you not participate in any dangerous activities given your recent bleed and your hemophilia. Bleeding in hemophiliacs has more potential to be life-threatening. Please get your blood counts checked at ___ site on either ___ or ___. Follow up with your regular doctor early next week. Best wishes, Your ___ Care Team ",
         "Mr. ___ is a ___ with history of mild FVIII deficiency who presents after snowboarding accident with multiple hematomas and falling hemoglobin concerning for ongoing bleeding. # FACTOR VIII DEFICIENCY, MULTIPLE HEMATOMAS: Patient presented after recent snowboarding accident. At ___ ___, imaging was notable for neck and shoulder hematomas. Upon reevaluation by his PCP, the patient was found to have a flank hematoma. Given falling hemoglobin, there was concern for retroperitoneal bleed. CTAP in the ED demonstrated hematoma over his flank musculature, but no active extravasation. He was given IV DDAVP, but FVIII activity was 103 (wnl). CBC remained stable and patient declined further inpatient monitoring. Atrius hematology recommended continued outpatient hemoglobin monitoring, but did not think further DDAVP was indicated given normal FVIII level. # TRANISTIONAL ISSUES: - PCP ___ ___ - CBC ___ - ___ at ___ - Caution to avoid dangerous activity - Code: presumed full - Emergency Contact: ___ ___ - wife) ",
         "1961",
         "230"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>target_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032-DS-21</td>\n",
       "      <td>&lt;SEX&gt; F &lt;SERVICE&gt; MEDICINE &lt;ALLERGIES&gt; No Know...</td>\n",
       "      <td>___ HCV cirrhosis c/b ascites, hiv on ART, h/o...</td>\n",
       "      <td>1946</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032-DS-22</td>\n",
       "      <td>&lt;SEX&gt; F &lt;SERVICE&gt; MEDICINE &lt;ALLERGIES&gt; Percoce...</td>\n",
       "      <td>___ with HIV on HAART, HCV cirrhosis with asci...</td>\n",
       "      <td>2183</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000117-DS-21</td>\n",
       "      <td>&lt;SEX&gt; F &lt;SERVICE&gt; MEDICINE &lt;ALLERGIES&gt; omepraz...</td>\n",
       "      <td>Ms. ___ is a ___ with history of GERD who pres...</td>\n",
       "      <td>1060</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000117-DS-22</td>\n",
       "      <td>&lt;SEX&gt; F &lt;SERVICE&gt; ORTHOPAEDICS &lt;ALLERGIES&gt; ome...</td>\n",
       "      <td>The patient presented to the emergency departm...</td>\n",
       "      <td>1195</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000248-DS-10</td>\n",
       "      <td>&lt;SEX&gt; M &lt;SERVICE&gt; MEDICINE &lt;ALLERGIES&gt; No Know...</td>\n",
       "      <td>Mr. ___ is a ___ with history of mild FVIII de...</td>\n",
       "      <td>1961</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          note_id                                              input  \\\n",
       "0  10000032-DS-21  <SEX> F <SERVICE> MEDICINE <ALLERGIES> No Know...   \n",
       "1  10000032-DS-22  <SEX> F <SERVICE> MEDICINE <ALLERGIES> Percoce...   \n",
       "2  10000117-DS-21  <SEX> F <SERVICE> MEDICINE <ALLERGIES> omepraz...   \n",
       "3  10000117-DS-22  <SEX> F <SERVICE> ORTHOPAEDICS <ALLERGIES> ome...   \n",
       "4  10000248-DS-10  <SEX> M <SERVICE> MEDICINE <ALLERGIES> No Know...   \n",
       "\n",
       "                                              target  input_tokens  \\\n",
       "0  ___ HCV cirrhosis c/b ascites, hiv on ART, h/o...          1946   \n",
       "1  ___ with HIV on HAART, HCV cirrhosis with asci...          2183   \n",
       "2  Ms. ___ is a ___ with history of GERD who pres...          1060   \n",
       "3  The patient presented to the emergency departm...          1195   \n",
       "4  Mr. ___ is a ___ with history of mild FVIII de...          1961   \n",
       "\n",
       "   target_tokens  \n",
       "0            231  \n",
       "1            810  \n",
       "2            172  \n",
       "3            330  \n",
       "4            230  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading CSV file using pandas\n",
    "# Basic usage:\n",
    "df = pd.read_csv(r\"D:\\UT_Austin\\sem4\\physionet.org\\files\\labelled-notes-hospital-course\\1.1.0\\mimic-iv-bhc.csv\")\n",
    "\n",
    "print(\"CSV file loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "df.head()  # Display first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67627d9",
   "metadata": {},
   "source": [
    "Basic cleaning / normalization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "da8ff978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_whitespace(text: str) -> str:\n",
    "    # collapse multiple spaces / newlines into single\n",
    "    text = re.sub(r'\\r', ' ', text)\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def clean_placeholders(text: str) -> str:\n",
    "    # e.g. ensure consistent casing / spacing around placeholders\n",
    "    # This is generic; adapt if you have more placeholder variants\n",
    "    text = re.sub(r'<\\s*SEX\\s*>', '<SEX>', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'<\\s*SERVICE\\s*>', '<SERVICE>', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'<\\s*ALLERGIES\\s*>', '<ALLERGIES>', text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "def remove_control_characters(text: str) -> str:\n",
    "    # remove non-printable / weird control chars\n",
    "    # e.g. anything in category Cc except \\n\n",
    "    cleaned = ''.join(ch for ch in text if (ch == '\\n' or (ord(ch) >= 32 and ord(ch) != 127)))\n",
    "    return cleaned\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    text = normalize_whitespace(text)\n",
    "    text = clean_placeholders(text)\n",
    "    text = remove_control_characters(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c911c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_clean'] = df['input'].map(preprocess_text)\n",
    "df['target_clean'] = df['target'].map(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e59d80",
   "metadata": {},
   "source": [
    "Filtering / dropping low-quality / edge examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5d78446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop examples where input or target is empty / very short\n",
    "MIN_INPUT_TOKENS = 50\n",
    "MIN_TARGET_TOKENS = 20\n",
    "\n",
    "mask_good = (df['input_clean'].map(len) > MIN_INPUT_TOKENS) & \\\n",
    "            (df['target_clean'].map(len) > MIN_TARGET_TOKENS)\n",
    "\n",
    "df = df[mask_good].copy()\n",
    "\n",
    "# Optionally: drop outliers where target is longer than input (if that happens)\n",
    "df = df[df['target_tokens'] < df['input_tokens'] * 1.2]  # example threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983aefc6",
   "metadata": {},
   "source": [
    "Tokenization & truncation / handling long inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f8dfb785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ajays\\anaconda3\\envs\\py311_cuda_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup successful! Input shape: torch.Size([2048]), Labels shape: torch.Size([285])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Falconsai/medical_summarization\")  # e.g. “t5-base”, “llama-…”, etc.\n",
    "# You'll also need the model itself\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Falconsai/medical_summarization\")\n",
    "MAX_INPUT_LEN = 2048  # adjust depending on your model capacity\n",
    "MAX_TARGET_LEN = 512  # adjust\n",
    "\n",
    "def encode_example(input_text: str, target_text: str):\n",
    "    # encode input and target, with truncation if too long\n",
    "    enc = tokenizer(\n",
    "        input_text,\n",
    "        truncation=True,\n",
    "        max_length=MAX_INPUT_LEN,\n",
    "        padding=False,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    dec = tokenizer(\n",
    "        target_text,\n",
    "        truncation=True,\n",
    "        max_length=MAX_TARGET_LEN,\n",
    "        padding=False,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    return {\n",
    "        'input_ids': enc.input_ids.squeeze(0),\n",
    "        'attention_mask': enc.attention_mask.squeeze(0),\n",
    "        'labels': dec.input_ids.squeeze(0)\n",
    "    }\n",
    "\n",
    "# Example application\n",
    "encoded = encode_example(df.iloc[0]['input_clean'], df.iloc[0]['target_clean'])\n",
    "print(f\"Setup successful! Input shape: {encoded['input_ids'].shape}, Labels shape: {encoded['labels'].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5d8dea",
   "metadata": {},
   "source": [
    "Creating dataset variants (full, section-filtered, chunked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc9d0c7",
   "metadata": {},
   "source": [
    "4.1 Section filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "918359d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: extract “HOSPITAL COURSE” section if present\n",
    "def extract_section(text: str, section_header: str) -> str:\n",
    "    # naive: split by the header and then stop when next header appears\n",
    "    # This assumes section headers in uppercase and followed by colon, e.g. “HOSPITAL COURSE:”\n",
    "    pattern = rf\"{section_header}\\s*:\"\n",
    "    parts = re.split(pattern, text, flags=re.IGNORECASE)\n",
    "    if len(parts) <= 1:\n",
    "        return \"\"  # section not found\n",
    "    rest = parts[1]\n",
    "    # Now stop when you see another section header (e.g. all caps + colon)\n",
    "    # e.g. next_header = uppercase letters + colon\n",
    "    m = re.search(r\"\\n[A-Z ]{3,50}:\\s\", rest)\n",
    "    if m:\n",
    "        rest = rest[: m.start()]\n",
    "    return rest.strip()\n",
    "\n",
    "# Example: create version of input using only “HOSPITAL COURSE” section\n",
    "df['section_hcourse'] = df['input_clean'].map(lambda x: extract_section(x, \"HOSPITAL COURSE\"))\n",
    "\n",
    "# Use that as an alternative input version if not empty, else fallback to full\n",
    "df['input_section_or_full'] = df.apply(lambda row: row['section_hcourse'] if len(row['section_hcourse']) > 0 else row['input_clean'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca33e27",
   "metadata": {},
   "source": [
    "4.2 Chunking / sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "23872934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 3\n"
     ]
    }
   ],
   "source": [
    "def chunk_input(input_ids: torch.Tensor, attention_mask: torch.Tensor, chunk_size: int, stride: int = None):\n",
    "    # Returns list of (chunk_input_ids, chunk_masks)\n",
    "    if stride is None:\n",
    "        stride = chunk_size  # non overlapping\n",
    "    chunks = []\n",
    "    L = input_ids.size(0)\n",
    "    start = 0\n",
    "    while start < L:\n",
    "        end = min(start + chunk_size, L)\n",
    "        chunk_ids = input_ids[start:end]\n",
    "        chunk_mask = attention_mask[start:end]\n",
    "        chunks.append((chunk_ids, chunk_mask))\n",
    "        if end == L:\n",
    "            break\n",
    "        start += stride\n",
    "    return chunks\n",
    "\n",
    "# Example: for each example, produce chunks\n",
    "CHUNK_SIZE = 1024\n",
    "STRIDE = 512\n",
    "\n",
    "row = encoded  # from earlier encode_example\n",
    "input_ids = row['input_ids']\n",
    "mask = row['attention_mask']\n",
    "chunks = chunk_input(input_ids, mask, CHUNK_SIZE, STRIDE)\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352d5e8f",
   "metadata": {},
   "source": [
    "Custom Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "799862d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BHC_Dataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_input_len=2048, max_target_len=512, variant=\"full\"):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_len = max_input_len\n",
    "        self.max_target_len = max_target_len\n",
    "        self.variant = variant  # e.g. \"full\", \"section_filtered\", etc.\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        if self.variant == \"section_filtered\":\n",
    "            input_text = row.get('input_section_or_full', row['input_clean'])\n",
    "        else:\n",
    "            input_text = row['input_clean']\n",
    "        target_text = row['target_clean']\n",
    "        enc = self.tokenizer(\n",
    "            input_text,\n",
    "            truncation=True,\n",
    "            max_length=self.max_input_len,\n",
    "            padding=False,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        dec = self.tokenizer(\n",
    "            target_text,\n",
    "            truncation=True,\n",
    "            max_length=self.max_target_len,\n",
    "            padding=False,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        item = {\n",
    "            'input_ids': enc.input_ids.squeeze(0),\n",
    "            'attention_mask': enc.attention_mask.squeeze(0),\n",
    "            'labels': dec.input_ids.squeeze(0)\n",
    "        }\n",
    "        return item\n",
    "\n",
    "# Example usage\n",
    "ds = BHC_Dataset(df, tokenizer, max_input_len=2048, max_target_len=512, variant=\"full\")\n",
    "dl = DataLoader(ds, batch_size=4, shuffle=True, collate_fn=lambda x: x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c4a60c",
   "metadata": {},
   "source": [
    "Logging / Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "84dbc71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_stats(df_before: pd.DataFrame, df_after: pd.DataFrame, step_name: str):\n",
    "    print(f\"Step: {step_name}\")\n",
    "    print(f\"Before: {len(df_before)} examples\")\n",
    "    print(f\"After: {len(df_after)} examples\")\n",
    "    dropped = len(df_before) - len(df_after)\n",
    "    print(f\"Dropped: {dropped} examples ({100 * dropped / len(df_before):.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a3e18f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: drop short / empty examples\n",
      "Before: 269059 examples\n",
      "After: 269059 examples\n",
      "Dropped: 0 examples (0.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajays\\AppData\\Local\\Temp\\ipykernel_21684\\2926529693.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df = df[mask_good].copy()\n"
     ]
    }
   ],
   "source": [
    "df0 = df.copy()\n",
    "# filtering step\n",
    "df = df[mask_good].copy()\n",
    "log_stats(df0, df, \"drop short / empty examples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "96cd95e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"bhc_preprocessed_v1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "660cb081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text, max_input_length=1024, max_summary_length=256):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\",\n",
    "                       truncation=True, max_length=max_input_length, \n",
    "                       padding=True)  # or pad to a min batch size\n",
    "    output = model.generate(**inputs, max_length=max_summary_length, \n",
    "                            num_beams=2, early_stopping=True)\n",
    "    summary = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2a1d8f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SEX> F <SERVICE> MEDICINE <ALLERGIES> No Known Allergies / Adverse Drug Reactions <ATTENDING> ___ <CHIEF COMPLAINT> Worsening ABD distension and pain <MAJOR SURGICAL OR INVASIVE PROCEDURE> Paracentesis <HISTORY OF PRESENT ILLNESS> ___ HCV cirrhosis c/b ascites, hiv on ART, h/o IVDU, COPD, bioplar, PTSD, presented from OSH ED with worsening abd distension over past week. Pt reports self-discontinuing lasix and spirnolactone ___ weeks ago, because she feels like \"they don't do anything\" and that she \"doesn't want to put more chemicals in her.\" She does not follow Na-restricted diets. In the past week, she notes that she has been having worsening abd distension and discomfort. She denies ___ edema, or SOB, or orthopnea. She denies f/c/n/v, d/c, dysuria. She had food poisoning a week ago from eating stale cake (n/v 20 min after food ingestion), which resolved the same day. She denies other recent illness or sick contacts. She notes that she has been noticing gum bleeding while brushing her teeth in recent weeks. she denies easy bruising, melena, BRBPR, hemetesis, hemoptysis, or hematuria. Because of her abd pain, she went to OSH ED and was transferred to ___ for further care. Per ED report, pt has brief period of confusion - she did not recall the ultrasound or bloodwork at osh. She denies recent drug use or alcohol use. She denies feeling confused, but reports that she is forgetful at times. In the ED, initial vitals were 98.4 70 106/63 16 97%RA Labs notable for ALT/AST/AP ___ ___: ___, Tbili1.6, WBC 5K, platelet 77, INR 1.6 <PAST MEDICAL HISTORY> 1. HCV Cirrhosis 2. No history of abnormal Pap smears. 3. She had calcification in her breast, which was removed previously and per patient not, it was benign. 4. For HIV disease, she is being followed by Dr. ___ Dr. ___. 5. COPD 6. Past history of smoking. 7. She also had a skin lesion, which was biopsied and showed skin cancer per patient report and is scheduled for a complete removal of the skin lesion in ___ of this year. 8. She also had another lesion in her forehead with purple discoloration. It was biopsied to exclude the possibility of ___'s sarcoma, the results is pending. 9. A 15 mm hypoechoic lesion on her ultrasound on ___ and is being monitored by an MRI. 10. History of dysplasia of anus in ___. 11. Bipolar affective disorder, currently manic, mild, and PTSD. 12. History of cocaine and heroin use. <SOCIAL HISTORY> ___ <FAMILY HISTORY> She a total of five siblings, but she is not talking to most of them. She only has one brother that she is in touch with and lives in ___. She is not aware of any known GI or liver disease in her family. Her last alcohol consumption was one drink two months ago. No regular alcohol consumption. Last drug use ___ years ago. She quit smoking a couple of years ago. <PHYSICAL EXAM> VS: 98.1 107/61 78 18 97RA General: in NAD HEENT: CTAB, anicteric sclera, OP clear Neck: supple, no LAD CV: RRR,S1S2, no m/r/g Lungs: CTAb, prolonged expiratory phase, no w/r/r Abdomen: distended, mild diffuse tenderness, +flank dullness, cannot percuss liver/spleen edge ___ distension GU: no foley Ext: wwp, no c/e/e, + clubbing Neuro: AAO3, converse normally, able to recall 3 times after 5 minutes, CN II-XII intact Discharge: PHYSICAL EXAMINATION: VS: 98 105/70 95 General: in NAD HEENT: anicteric sclera, OP clear Neck: supple, no LAD CV: RRR,S1S2, no m/r/g Lungs: CTAb, prolonged expiratory phase, no w/r/r Abdomen: distended but improved, TTP in RUQ, GU: no foley Ext: wwp, no c/e/e, + clubbing Neuro: AAO3, CN II-XII intact <PERTINENT RESULTS> ___ 10: 25PM GLUCOSE-109* UREA N-25* CREAT-0.3* SODIUM-138 POTASSIUM-3.4 CHLORIDE-105 TOTAL CO2-27 ANION GAP-9 ___ 10: 25PM estGFR-Using this ___ 10: 25PM ALT(SGPT)-100* AST(SGOT)-114* ALK PHOS-114* TOT BILI-1.6* ___ 10: 25PM LIPASE-77* ___ 10: 25PM ALBUMIN-3.3* ___ 10: 25PM WBC-5.0# RBC-4.29 HGB-14.3 HCT-42.6 MCV-99* MCH-33.3* MCHC-33.5 RDW-15.7* ___ 10: 25PM NEUTS-70.3* LYMPHS-16.5* MONOS-8.1 EOS-4.2* BASOS-0.8 ___ 10: 25PM PLT COUNT-71* ___ 10: 25PM ___ PTT-30.9 ___ ___ 10: 25PM ___ . CXR: No acute cardiopulmonary process. U/S: 1. Nodular appearance of the liver compatible with cirrhosis. Signs of portal hypertension including small amount of ascites and splenomegaly. 2. Cholelithiasis. 3. Patent portal veins with normal hepatopetal flow. Diagnostic para attempted in the ED, unsuccessful. On the floor, pt c/o abd distension and discomfort. <MEDICATIONS ON ADMISSION> The Preadmission Medication list is accurate and complete. 1. Furosemide 20 mg PO DAILY 2. Spironolactone 50 mg PO DAILY 3. Albuterol Inhaler 2 PUFF IH Q4H: PRN wheezing, SOB 4. Raltegravir 400 mg PO BID 5. Emtricitabine-Tenofovir (Truvada) 1 TAB PO DAILY 6. Nicotine Patch 14 mg TD DAILY 7. Ipratropium Bromide Neb 1 NEB IH Q6H SOB <DISCHARGE MEDICATIONS> 1. Albuterol Inhaler 2 PUFF IH Q4H: PRN wheezing, SOB 2. Emtricitabine-Tenofovir (Truvada) 1 TAB PO DAILY 3. Furosemide 40 mg PO DAILY RX *furosemide 40 mg 1 tablet(s) by mouth Daily Disp #*30 Tablet Refills: *3 4. Ipratropium Bromide Neb 1 NEB IH Q6H SOB 5. Nicotine Patch 14 mg TD DAILY 6. Raltegravir 400 mg PO BID 7. Spironolactone 50 mg PO DAILY 8. Acetaminophen 500 mg PO Q6H: PRN pain <DISCHARGE DISPOSITION> Home <DISCHARGE DIAGNOSIS> Ascites from Portal HTN <DISCHARGE CONDITION> Mental Status: Clear and coherent. Level of Consciousness: Alert and interactive. Activity Status: Ambulatory - Independent. <FOLLOWUP INSTRUCTIONS> ___ <DISCHARGE INSTRUCTIONS> Dear Ms. ___, It was a pleasure taking care of you! You came to us with stomach pain and worsening distension. While you were here we did a paracentesis to remove 1.5L of fluid from your belly. We also placed you on you 40 mg of Lasix and 50 mg of Aldactone to help you urinate the excess fluid still in your belly. As we discussed, everyone has a different dose of lasix required to make them urinate and it's likely that you weren't taking a high enough dose. Please take these medications daily to keep excess fluid off and eat a low salt diet. You will follow up with Dr. ___ in liver clinic and from there have your colonoscopy and EGD scheduled. Of course, we are always here if you need us. We wish you all the best! Your ___ Team.\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0]['input_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0c27c73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEX> SERVICE> MEDICINE ALLERGIES> No Known Allergies / Adverse Drug Reactions ATTENDING> ___ CHIEF COMPLAINT> Worsening abd distension and pain MAJOR SURGICAL OR INVASIVE PROCEDURE> Paracentesis HISTORY OF PRESENT ILLNESS> ___ HCV cirrhosis c/b ascites, hiv on ART, h/o IVDU, COPD, bioplar, PTSD, presented from OSH ED with worsening abd distension over past week.\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "instruction = (\n",
    "    \"Summarize the following hospital discharge note into a concise, factual \"\n",
    "    \"Brief Hospital Course summary:\\n\\n\"\n",
    ")\n",
    "summary = summarize(instruction + df.iloc[0]['input_clean'], max_input_length=1024, max_summary_length=300)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99b45ff",
   "metadata": {},
   "source": [
    "Train / Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0b2d376a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Training length: 242153 | Original Validation Length: 26906\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "print(f\"Original Training length: {len(train_df)} | Original Validation Length: {len(val_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd2ad78",
   "metadata": {},
   "source": [
    "sample the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6372d58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.sample(2000, random_state=42)\n",
    "# val_df = val_df.sample(500, random_state=42)\n",
    "# print(f\"Sampled Training length: {len(train_df)} | Sampled Validation Length: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c98fc6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ajays\\anaconda3\\envs\\py311_cuda_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"Falconsai/medical_summarization\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,use_fast=True)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)  # This is PyTorch by default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d3ef4af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_input_len=1024, max_target_len=256):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_len = max_input_len\n",
    "        self.max_target_len = max_target_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        inputs = tokenizer(\n",
    "            row[\"input_clean\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_input_len,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        targets = tokenizer(\n",
    "            row[\"target_clean\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_target_len,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": inputs.input_ids.squeeze(),\n",
    "            \"attention_mask\": inputs.attention_mask.squeeze(),\n",
    "            \"labels\": targets.input_ids.squeeze(),\n",
    "        }\n",
    "\n",
    "train_dataset = SummarizationDataset(train_df, tokenizer)\n",
    "val_dataset = SummarizationDataset(val_df, tokenizer)\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971ff9bf",
   "metadata": {},
   "source": [
    "Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7269622e",
   "metadata": {},
   "source": [
    "LORA config adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "01a4e5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU optimizations enabled\n"
     ]
    }
   ],
   "source": [
    "# Enable optimizations\n",
    "torch.backends.cudnn.benchmark = True     # Good for fixed input sizes\n",
    "torch.backends.cuda.matmul.allow_tf32 = True  # Good for newer GPUs\n",
    "# Safe GPU optimizations\n",
    "try:\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        if hasattr(torch.backends.cuda.matmul, 'allow_tf32'):\n",
    "            torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        print(\"✅ GPU optimizations enabled\")\n",
    "    else:\n",
    "        print(\"⚠️ CUDA not available, skipping GPU optimizations\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Could not enable optimizations: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2c420173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    ")\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "174ea805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0353373d0ae0482c94394d7d532d7e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "c:\\Users\\ajays\\anaconda3\\envs\\py311_cuda_env\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:52:27] Step 200: Loss = 4.6693\n",
      "{'loss': 4.6693, 'learning_rate': 4.967407210323268e-05, 'epoch': 0.01}\n",
      "[08:58:08] Step 400: Loss = 3.9221\n",
      "{'loss': 3.9221, 'learning_rate': 4.9008913130238126e-05, 'epoch': 0.03}\n",
      "[09:03:40] Step 600: Loss = 3.7591\n",
      "{'loss': 3.7591, 'learning_rate': 4.834375415724358e-05, 'epoch': 0.04}\n",
      "[09:09:13] Step 800: Loss = 3.6854\n",
      "{'loss': 3.6854, 'learning_rate': 4.768192097911401e-05, 'epoch': 0.05}\n",
      "[09:14:51] Step 1000: Loss = 3.6661\n",
      "{'loss': 3.6661, 'learning_rate': 4.7016762006119464e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb229d3869044feac3fe8444fbea8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6727 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:27:59] Step 1000: Eval Loss = 3.4089\n",
      "{'eval_loss': 3.4088950157165527, 'eval_runtime': 787.5448, 'eval_samples_per_second': 34.164, 'eval_steps_per_second': 8.542, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ajays\\anaconda3\\envs\\py311_cuda_env\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:32] Step 1200: Loss = 3.6195\n",
      "{'loss': 3.6195, 'learning_rate': 4.635160303312492e-05, 'epoch': 0.08}\n",
      "[09:39:10] Step 1400: Loss = 3.5908\n",
      "{'loss': 3.5908, 'learning_rate': 4.568644406013037e-05, 'epoch': 0.09}\n",
      "[09:44:47] Step 1600: Loss = 3.5882\n",
      "{'loss': 3.5882, 'learning_rate': 4.50246108820008e-05, 'epoch': 0.11}\n",
      "[09:50:24] Step 1800: Loss = 3.5732\n",
      "{'loss': 3.5732, 'learning_rate': 4.4359451909006256e-05, 'epoch': 0.12}\n",
      "[09:56:01] Step 2000: Loss = 3.5446\n",
      "{'loss': 3.5446, 'learning_rate': 4.369429293601171e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97aade3b998f405db36056492155d1bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6727 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:09:04] Step 2000: Eval Loss = 3.3187\n",
      "{'eval_loss': 3.3187360763549805, 'eval_runtime': 783.3279, 'eval_samples_per_second': 34.348, 'eval_steps_per_second': 8.588, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ajays\\anaconda3\\envs\\py311_cuda_env\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:14:40] Step 2200: Loss = 3.5374\n",
      "{'loss': 3.5374, 'learning_rate': 4.302913396301716e-05, 'epoch': 0.15}\n",
      "[10:20:15] Step 2400: Loss = 3.5109\n",
      "{'loss': 3.5109, 'learning_rate': 4.236397499002262e-05, 'epoch': 0.16}\n",
      "[10:25:51] Step 2600: Loss = 3.4881\n",
      "{'loss': 3.4881, 'learning_rate': 4.169881601702807e-05, 'epoch': 0.17}\n",
      "[10:31:26] Step 2800: Loss = 3.4950\n",
      "{'loss': 3.495, 'learning_rate': 4.1033657044033525e-05, 'epoch': 0.19}\n",
      "[10:36:53] Step 3000: Loss = 3.4866\n",
      "{'loss': 3.4866, 'learning_rate': 4.036849807103898e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9bb8f9e83c1414393c7fb5abf439ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6727 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:52] Step 3000: Eval Loss = 3.2640\n",
      "{'eval_loss': 3.2639641761779785, 'eval_runtime': 779.4557, 'eval_samples_per_second': 34.519, 'eval_steps_per_second': 8.63, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ajays\\anaconda3\\envs\\py311_cuda_env\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:55:28] Step 3200: Loss = 3.4777\n",
      "{'loss': 3.4777, 'learning_rate': 3.970333909804443e-05, 'epoch': 0.21}\n",
      "[11:01:03] Step 3400: Loss = 3.4725\n",
      "{'loss': 3.4725, 'learning_rate': 3.903818012504989e-05, 'epoch': 0.22}\n",
      "[11:06:38] Step 3600: Loss = 3.4624\n",
      "{'loss': 3.4624, 'learning_rate': 3.837302115205535e-05, 'epoch': 0.24}\n",
      "[11:12:15] Step 3800: Loss = 3.4404\n",
      "{'loss': 3.4404, 'learning_rate': 3.77078621790608e-05, 'epoch': 0.25}\n",
      "[11:17:51] Step 4000: Loss = 3.4249\n",
      "{'loss': 3.4249, 'learning_rate': 3.7042703206066255e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e593e7743c40caaba48087959979fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6727 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:52] Step 4000: Eval Loss = 3.2266\n",
      "{'eval_loss': 3.2266054153442383, 'eval_runtime': 780.4214, 'eval_samples_per_second': 34.476, 'eval_steps_per_second': 8.62, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ajays\\anaconda3\\envs\\py311_cuda_env\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:36:27] Step 4200: Loss = 3.4097\n",
      "{'loss': 3.4097, 'learning_rate': 3.63775442330717e-05, 'epoch': 0.28}\n",
      "[11:42:04] Step 4400: Loss = 3.4158\n",
      "{'loss': 3.4158, 'learning_rate': 3.5712385260077156e-05, 'epoch': 0.29}\n",
      "[11:47:40] Step 4600: Loss = 3.4237\n",
      "{'loss': 3.4237, 'learning_rate': 3.504722628708261e-05, 'epoch': 0.3}\n",
      "[11:53:15] Step 4800: Loss = 3.4155\n",
      "{'loss': 3.4155, 'learning_rate': 3.438206731408807e-05, 'epoch': 0.32}\n",
      "[11:58:52] Step 5000: Loss = 3.3958\n",
      "{'loss': 3.3958, 'learning_rate': 3.3716908341093525e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf3619f48ac4697893c5e8ba4a3e867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6727 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:11:51] Step 5000: Eval Loss = 3.1967\n",
      "{'eval_loss': 3.1966910362243652, 'eval_runtime': 779.546, 'eval_samples_per_second': 34.515, 'eval_steps_per_second': 8.629, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ajays\\anaconda3\\envs\\py311_cuda_env\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:17:23] Step 5200: Loss = 3.4009\n",
      "{'loss': 3.4009, 'learning_rate': 3.305174936809898e-05, 'epoch': 0.34}\n",
      "[12:22:50] Step 5400: Loss = 3.3680\n",
      "{'loss': 3.368, 'learning_rate': 3.238659039510443e-05, 'epoch': 0.36}\n",
      "[12:28:24] Step 5600: Loss = 3.4034\n",
      "{'loss': 3.4034, 'learning_rate': 3.1721431422109886e-05, 'epoch': 0.37}\n",
      "[12:33:58] Step 5800: Loss = 3.4047\n",
      "{'loss': 3.4047, 'learning_rate': 3.105627244911534e-05, 'epoch': 0.38}\n",
      "[12:39:32] Step 6000: Loss = 3.3736\n",
      "{'loss': 3.3736, 'learning_rate': 3.039111347612079e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00eade203d04c53bfa6afd56e70ee96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6727 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:52:30] Step 6000: Eval Loss = 3.1707\n",
      "{'eval_loss': 3.1706550121307373, 'eval_runtime': 777.8587, 'eval_samples_per_second': 34.59, 'eval_steps_per_second': 8.648, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ajays\\anaconda3\\envs\\py311_cuda_env\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:58:05] Step 6200: Loss = 3.3642\n",
      "{'loss': 3.3642, 'learning_rate': 2.9725954503126248e-05, 'epoch': 0.41}\n",
      "[13:03:40] Step 6400: Loss = 3.3659\n",
      "{'loss': 3.3659, 'learning_rate': 2.9060795530131702e-05, 'epoch': 0.42}\n",
      "[13:09:15] Step 6600: Loss = 3.3771\n",
      "{'loss': 3.3771, 'learning_rate': 2.8395636557137156e-05, 'epoch': 0.44}\n",
      "[13:14:49] Step 6800: Loss = 3.3611\n",
      "{'loss': 3.3611, 'learning_rate': 2.773047758414261e-05, 'epoch': 0.45}\n",
      "[13:20:24] Step 7000: Loss = 3.3717\n",
      "{'loss': 3.3717, 'learning_rate': 2.7065318611148067e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668a800ac498492ab8dc65e331dffcfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6727 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:33:20] Step 7000: Eval Loss = 3.1493\n",
      "{'eval_loss': 3.1492719650268555, 'eval_runtime': 775.308, 'eval_samples_per_second': 34.704, 'eval_steps_per_second': 8.677, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ajays\\anaconda3\\envs\\py311_cuda_env\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:38:55] Step 7200: Loss = 3.3637\n",
      "{'loss': 3.3637, 'learning_rate': 2.640015963815352e-05, 'epoch': 0.48}\n",
      "[13:44:30] Step 7400: Loss = 3.3744\n",
      "{'loss': 3.3744, 'learning_rate': 2.5735000665158975e-05, 'epoch': 0.49}\n",
      "[13:50:06] Step 7600: Loss = 3.3739\n",
      "{'loss': 3.3739, 'learning_rate': 2.5069841692164432e-05, 'epoch': 0.5}\n",
      "[13:55:42] Step 7800: Loss = 3.3527\n",
      "{'loss': 3.3527, 'learning_rate': 2.4408008514034856e-05, 'epoch': 0.52}\n",
      "[14:01:20] Step 8000: Loss = 3.3541\n",
      "{'loss': 3.3541, 'learning_rate': 2.374284954104031e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3641aa8e5d41c3916957a3565691a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6727 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:14:19] Step 8000: Eval Loss = 3.1320\n",
      "{'eval_loss': 3.1320409774780273, 'eval_runtime': 779.3039, 'eval_samples_per_second': 34.526, 'eval_steps_per_second': 8.632, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ajays\\anaconda3\\envs\\py311_cuda_env\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:19:55] Step 8200: Loss = 3.3391\n",
      "{'loss': 3.3391, 'learning_rate': 2.3077690568045767e-05, 'epoch': 0.54}\n",
      "[14:25:32] Step 8400: Loss = 3.3444\n",
      "{'loss': 3.3444, 'learning_rate': 2.2412531595051217e-05, 'epoch': 0.56}\n",
      "[14:31:09] Step 8600: Loss = 3.3400\n",
      "{'loss': 3.34, 'learning_rate': 2.1750698416921644e-05, 'epoch': 0.57}\n",
      "[14:36:45] Step 8800: Loss = 3.3704\n",
      "{'loss': 3.3704, 'learning_rate': 2.1085539443927098e-05, 'epoch': 0.58}\n",
      "[14:42:22] Step 9000: Loss = 3.3378\n",
      "{'loss': 3.3378, 'learning_rate': 2.0420380470932555e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bb33384cae45568cc1858439823618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6727 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:55:20] Step 9000: Eval Loss = 3.1172\n",
      "{'eval_loss': 3.117156505584717, 'eval_runtime': 778.0574, 'eval_samples_per_second': 34.581, 'eval_steps_per_second': 8.646, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ajays\\anaconda3\\envs\\py311_cuda_env\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:00:59] Step 9200: Loss = 3.3499\n",
      "{'loss': 3.3499, 'learning_rate': 1.975522149793801e-05, 'epoch': 0.61}\n",
      "[15:06:36] Step 9400: Loss = 3.3240\n",
      "{'loss': 3.324, 'learning_rate': 1.909006252494346e-05, 'epoch': 0.62}\n",
      "[15:12:15] Step 9600: Loss = 3.3560\n",
      "{'loss': 3.356, 'learning_rate': 1.8424903551948917e-05, 'epoch': 0.63}\n",
      "[15:17:52] Step 9800: Loss = 3.3163\n",
      "{'loss': 3.3163, 'learning_rate': 1.775974457895437e-05, 'epoch': 0.65}\n",
      "[15:23:30] Step 10000: Loss = 3.2980\n",
      "{'loss': 3.298, 'learning_rate': 1.7094585605959825e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6793234ea224492c9caba4bd0695206b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6727 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:36:30] Step 10000: Eval Loss = 3.1070\n",
      "{'eval_loss': 3.1070311069488525, 'eval_runtime': 779.4766, 'eval_samples_per_second': 34.518, 'eval_steps_per_second': 8.63, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ajays\\anaconda3\\envs\\py311_cuda_env\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:42:06] Step 10200: Loss = 3.3195\n",
      "{'loss': 3.3195, 'learning_rate': 1.6429426632965282e-05, 'epoch': 0.67}\n",
      "[15:47:45] Step 10400: Loss = 3.3145\n",
      "{'loss': 3.3145, 'learning_rate': 1.5764267659970732e-05, 'epoch': 0.69}\n",
      "[15:53:22] Step 10600: Loss = 3.3288\n",
      "{'loss': 3.3288, 'learning_rate': 1.5099108686976188e-05, 'epoch': 0.7}\n",
      "[15:58:59] Step 10800: Loss = 3.3164\n",
      "{'loss': 3.3164, 'learning_rate': 1.4433949713981642e-05, 'epoch': 0.71}\n",
      "[16:04:36] Step 11000: Loss = 3.3090\n",
      "{'loss': 3.309, 'learning_rate': 1.3768790740987098e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "accce2cd14584748965c77206ce9bafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6727 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:17:38] Step 11000: Eval Loss = 3.0974\n",
      "{'eval_loss': 3.097398042678833, 'eval_runtime': 781.8101, 'eval_samples_per_second': 34.415, 'eval_steps_per_second': 8.604, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ajays\\anaconda3\\envs\\py311_cuda_env\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:14] Step 11200: Loss = 3.3256\n",
      "{'loss': 3.3256, 'learning_rate': 1.310363176799255e-05, 'epoch': 0.74}\n",
      "[16:28:53] Step 11400: Loss = 3.3268\n",
      "{'loss': 3.3268, 'learning_rate': 1.2438472794998005e-05, 'epoch': 0.75}\n",
      "[16:34:31] Step 11600: Loss = 3.3116\n",
      "{'loss': 3.3116, 'learning_rate': 1.177331382200346e-05, 'epoch': 0.77}\n",
      "[16:40:10] Step 11800: Loss = 3.3169\n",
      "{'loss': 3.3169, 'learning_rate': 1.1108154849008915e-05, 'epoch': 0.78}\n",
      "[16:45:50] Step 12000: Loss = 3.3098\n",
      "{'loss': 3.3098, 'learning_rate': 1.0442995876014367e-05, 'epoch': 0.79}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2667b1e3fc9f4612a9446ab232faca50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6727 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:58:53] Step 12000: Eval Loss = 3.0911\n",
      "{'eval_loss': 3.0910980701446533, 'eval_runtime': 783.7654, 'eval_samples_per_second': 34.329, 'eval_steps_per_second': 8.583, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ajays\\anaconda3\\envs\\py311_cuda_env\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:04:30] Step 12200: Loss = 3.2782\n",
      "{'loss': 3.2782, 'learning_rate': 9.777836903019823e-06, 'epoch': 0.81}\n",
      "[17:10:00] Step 12400: Loss = 3.3264\n",
      "{'loss': 3.3264, 'learning_rate': 9.112677930025277e-06, 'epoch': 0.82}\n",
      "[17:15:34] Step 12600: Loss = 3.3101\n",
      "{'loss': 3.3101, 'learning_rate': 8.44751895703073e-06, 'epoch': 0.83}\n",
      "[17:21:15] Step 12800: Loss = 3.2932\n",
      "{'loss': 3.2932, 'learning_rate': 7.782359984036184e-06, 'epoch': 0.85}\n",
      "[17:26:56] Step 13000: Loss = 3.2950\n",
      "{'loss': 3.295, 'learning_rate': 7.11720101104164e-06, 'epoch': 0.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797c235380614c189be960525e3c3462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6727 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:39:55] Step 13000: Eval Loss = 3.0867\n",
      "{'eval_loss': 3.0867319107055664, 'eval_runtime': 779.4742, 'eval_samples_per_second': 34.518, 'eval_steps_per_second': 8.63, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ajays\\anaconda3\\envs\\py311_cuda_env\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:45:34] Step 13200: Loss = 3.3264\n",
      "{'loss': 3.3264, 'learning_rate': 6.452042038047093e-06, 'epoch': 0.87}\n",
      "[17:51:11] Step 13400: Loss = 3.3157\n",
      "{'loss': 3.3157, 'learning_rate': 5.790208859917521e-06, 'epoch': 0.89}\n",
      "[17:56:49] Step 13600: Loss = 3.3280\n",
      "{'loss': 3.328, 'learning_rate': 5.125049886922975e-06, 'epoch': 0.9}\n",
      "[18:02:25] Step 13800: Loss = 3.3108\n",
      "{'loss': 3.3108, 'learning_rate': 4.459890913928429e-06, 'epoch': 0.91}\n",
      "[18:08:02] Step 14000: Loss = 3.3200\n",
      "{'loss': 3.32, 'learning_rate': 3.7947319409338836e-06, 'epoch': 0.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8778a76e954d4a80878833943e214e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6727 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:21:01] Step 14000: Eval Loss = 3.0839\n",
      "{'eval_loss': 3.0838568210601807, 'eval_runtime': 778.9819, 'eval_samples_per_second': 34.54, 'eval_steps_per_second': 8.636, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ajays\\anaconda3\\envs\\py311_cuda_env\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:26:38] Step 14200: Loss = 3.3151\n",
      "{'loss': 3.3151, 'learning_rate': 3.129572967939338e-06, 'epoch': 0.94}\n",
      "[18:32:16] Step 14400: Loss = 3.2784\n",
      "{'loss': 3.2784, 'learning_rate': 2.4644139949447918e-06, 'epoch': 0.95}\n",
      "[18:37:54] Step 14600: Loss = 3.2953\n",
      "{'loss': 3.2953, 'learning_rate': 1.799255021950246e-06, 'epoch': 0.96}\n",
      "[18:43:32] Step 14800: Loss = 3.3097\n",
      "{'loss': 3.3097, 'learning_rate': 1.1340960489557006e-06, 'epoch': 0.98}\n",
      "[18:49:08] Step 15000: Loss = 3.3244\n",
      "{'loss': 3.3244, 'learning_rate': 4.6893707596115475e-07, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9889b61bf9444d91e2ce96fb380d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6727 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:02:12] Step 15000: Eval Loss = 3.0827\n",
      "{'eval_loss': 3.0826780796051025, 'eval_runtime': 783.5047, 'eval_samples_per_second': 34.341, 'eval_steps_per_second': 8.586, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ajays\\anaconda3\\envs\\py311_cuda_env\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 37175.6398, 'train_samples_per_second': 6.514, 'train_steps_per_second': 0.407, 'train_loss': 3.4158053352131117, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15134, training_loss=3.4158053352131117, metrics={'train_runtime': 37175.6398, 'train_samples_per_second': 6.514, 'train_steps_per_second': 0.407, 'train_loss': 3.4158053352131117, 'epoch': 1.0})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, TrainerCallback\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    warmup_steps=100,                      # 🔥 Add warmup for stability\n",
    "    # max_steps=300,                     # 🔥 Move max_steps here\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,                     # 🔥 enable mixed precision\n",
    "    save_total_limit=3,\n",
    "    report_to=\"none\",\n",
    "    dataloader_num_workers=0,      # fewer threads on Windows\n",
    "    logging_steps=200,\n",
    "    resume_from_checkpoint=True,  # 🔥 Add this\n",
    "    dataloader_pin_memory=False,           # 🔥 Reduce memory usage\n",
    "    remove_unused_columns=True,            # 🔥 Clean up unused data\n",
    "    gradient_checkpointing=True,           # 🔥 Trade compute for memory\n",
    "    optim=\"adamw_torch\",  # 🔥 Use non-deprecated AdamW\n",
    "\n",
    ")\n",
    "# Enhanced callback for longer training\n",
    "class EnhancedCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            # Add timestamp and step info\n",
    "            import datetime\n",
    "            timestamp = datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
    "            if 'loss' in logs:\n",
    "                print(f\"[{timestamp}] Step {state.global_step}: Loss = {logs['loss']:.4f}\")\n",
    "            if 'eval_loss' in logs:\n",
    "                print(f\"[{timestamp}] Step {state.global_step}: Eval Loss = {logs['eval_loss']:.4f}\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[EnhancedCallback()],\n",
    ")\n",
    "# -------------------------------\n",
    "# 8. Train (start small)\n",
    "# -------------------------------\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "57f21c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training complete and model saved.\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"./medical_summarizer_lora_v1\")\n",
    "tokenizer.save_pretrained(\"./medical_summarizer_lora_v1\")\n",
    "print(\"✅ Training complete and model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d122ece3",
   "metadata": {},
   "source": [
    "EVALUATION: rouge or bleu\n",
    "Common metrics available: \"bleu\", \"rouge\", \"meteor\", \"bertscore\", \"exact_match\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "73c86de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e5557a96d84b59ab606df65371d9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:25<00:00,  4.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.24322987122995235, 'rouge2': 0.061644801138736, 'rougeL': 0.15954732842055513, 'rougeLsum': 0.15995710914879385}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "def evaluate_model(dataset, num_samples=50):\n",
    "    model.eval()\n",
    "    preds, refs = [], []\n",
    "    for i in tqdm(range(num_samples)):\n",
    "        text = dataset.df.iloc[i][\"input_clean\"]\n",
    "        reference = dataset.df.iloc[i][\"target_clean\"]\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=2048).to(model.device)\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(**inputs, max_new_tokens=256)\n",
    "        pred = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        preds.append(pred)\n",
    "        refs.append(reference)\n",
    "    return metric.compute(predictions=preds, references=refs)\n",
    "\n",
    "results = evaluate_model(val_dataset, num_samples=30)\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
